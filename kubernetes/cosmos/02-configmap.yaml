apiVersion: v1
kind: ConfigMap
metadata:
  name: cosmos-config
  namespace: cosmos
  labels:
    app: cosmos
data:
  inference.yaml: |
    model:
      name: "cosmos"
      version: "latest"
    
    inference:
      batch_size: 8
      max_sequence_length: 2048
      gpu_memory_fraction: 0.9
      num_threads: 4
    
    server:
      port: 8080
      workers: 1
      timeout: 300
      max_concurrent_requests: 100
    
    logging:
      level: "INFO"
      format: "json"
